# MGE via snakemake with added functionality for BGE #
- Raw reads for 12 test samples can be downloaded [here](https://naturalhistorymuseum-my.sharepoint.com/personal/b_price_nhm_ac_uk/_layouts/15/onedrive.aspx?ct=1723035606962&or=Teams%2DHL&ga=1&LOF=1&id=%2Fpersonal%2Fb%5Fprice%5Fnhm%5Fac%5Fuk%2FDocuments%2F%5Ftemp%2F%5FBGEexamples4Felix%2F1%5Fraw%5Fdata). Each read pair must be in seperate subdirectories under a parent directory that can be called anything.
- Requires BGE_test_samples.csv (Snakefile and Snakefile2) and gene_fetch_BGE_test_data.csv (Snakefile2)
- Snakemake, TrimGalore, Exonerate, and numpy installed in conda env
- Run using snakemake.sh

## Running options: ##
**Snakefile:**
- Uses config.yaml
  - Contains path to 'BGE_test_samples.csv' (lists sample names, fwd and rev read paths, and an output directory)
  - Contains different parameter configurations for -s and -r.
- Uses insecta_cox1.fasta as protein reference (stored in protein_references dir).

**Snakefile2:** 
- Uses config2.yaml
  - Contains a path to 'BGE_test_samples_all.csv', an output directory, and 'gene_fetch_BGE_test_data.csv' (generated by 1_gene_fetch.py. Contains sample names, matched term, protein reference accession number, abs path to .fasta reference sequence, and reference name (i.e. Process ID).
- Uses taxa-specific references from 'gene_fetch_BGE_test_data.csv'. Stored in protein_references_2 dir.

## To do ##
- Get Snakefile2 working (i.e. so MGE can take a samples_file and protein_references_file containing taxa-specific references as input). Current issue relates to snakemake running samples and protein references 'all against all', as opposed to one sample and one corresponding reference (as listed in 'gene_fetch_BGE_test_data.csv').

See below for suggestions from Marie for fixes:
_Snakemake wants create the full factorial wildcard combinations (the all vs all issue):_
_I think there are different ways to approach this, but one convenient solution might be to add the zip argument in the expand() function which can be used to define how wildcards are combined.
Have a look at the FAQs https://uk01.l.antigena.com/l/7UWdvSuml33y0zzodngXWW0lKy-ZiJosuND7IIfwJZFbzqRlioq~scYbDghNUGlOtPuSEUzpsOhskfaoYAtsxI8P22vfuWAwG7K8IVzZIKyrJFGO3onMM_bfJ6DOUCZmhzZCl0CgfUUZa0IIyra9qE9-SY_Nxtr-n0HZoEEpYAoMU0dUGJyaVm  under "I donâ€™t want expand to use the product of every wildcard, what can I do?" However, I don't know how this behaves if you have also the {gene} wildcard in there..._

_Alternatively, you could use plain python coding to create the combinations you want as suggested here: https://stackoverflow.com/questions/75173778/restricting-wildcard-expansion-to-certain-combinations-in-snakemake. I think, in your case, I would try first the zip argument in the expand() function, but if this does not immediately work, I would directly fall back to python coding because you already added quite a lot of code in order to parse to sample info from the csv files. However, instead of creating 2 dicts, I would create one dict where sample ID is the key and all other information needed are stored in the value, e.g. as tuple or list ["fwd file", "rev file", "ref"]. Then you could access e.g. the reference info like this: dict[sample][2]. Or you do it in separate lists which retain the order of elements as suggested in the stackoverflow thread._


## MGE output post-processing ##
Python scripts to organise, trim, concatenate and calculate summary stats from MGE outputs.

### 4_mge_tidy-snakemake.py ###
Usage information output by running 'python 4_mge_tidy-snakemake.py'
- Organised files into subdirectories (alignment, consensus, err, logs, out) depending on file extension.
- Concatenates consensus.fas files together (within consensus subdir) and outputs user-specified multi.fasta (highly recommended to include 'cox1' in filename for downstream BOLDigger2 functionality).
- 'Cleans' and trims sequence headers of consenus sequences.

### 5_mge_stats-snakemake.py ###
Usage information output by running 'python 5_mge_stats-snakemake.py'
- Reads relevant fields from .out files in 'out' dir:
  -  consensus sequence output (i.e. process ID)
  -  Number of input sequences considered
  -  sequences found in vulgar file
  -  number of aligned reads
  -  number of skipped reads due to low rel. score (low relative score = read didn't pass exonerate relative score threshold (i.e. -r))
  -  length of alignment (i.e. reference sequence length)
  -  Coverage minimum
  -  Coverage maximum
  -  Coverage mean
  -  Coverage median
- Determines sequence stats from concatenated consensus.fasta generated by '4_mge_tidy-snakemake.py':
  - Sequence length (only GTACs)
  - N Count
  - Dash and Tilde Count
  - Non-GTAC Count (total of 'N Count' and 'Dash and Tilde Count')
- Parses BLASTn (against 'nt' DB) results:
  - BLAST Title (top hit sequence name)
  - BLAST Score (HSP score assigned to the alignment (higher = better)
  - BLAST alignment length
  - BLAST Identity (number of identical base matches between the query and subject sequences)
  - BLAST percent identity
  - BLAST Gaps
  - BLAST Query Coverage (range of positions in query (input) sequence covered by alignment)
  - BLAST Subject Coverage (range of positions in subject equence covered by alignment)
  - BLAST Accession (top hit accession number)

